"""
Main Anomaly Detection Page
"""
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from webapp.api_client import get_api_client
from webapp.utils.session_state import init_session_state, add_to_history, get_threshold, set_threshold
from webapp.utils.browser_notify import request_notification_permission
from webapp.components.visualizer import (
    plot_reconstruction_error,
    plot_fft_spectrum,
    plot_anomaly_distribution,
    plot_time_series
)
from webapp.components.alerts import show_anomaly_alert, show_error_alert, show_info_alert
from webapp.components.history_table import history_table_component

def get_failure_info(filename: str) -> dict:
    """íŒŒì¼ëª…ì—ì„œ ê³ ì¥ êµ¬ê°„ ì •ë³´ ì¶”ì¶œ"""
    import yaml
    import re
    
    try:
        # config.yaml ë¡œë“œ
        config_path = Path("configs/config.yaml")
        if not config_path.exists():
            return None
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # íŒŒì¼ëª…ì—ì„œ test_setê³¼ bearing_id ì¶”ì¶œ
        # ì˜ˆ: "1st_test_bearing_1.csv" ë˜ëŠ” "2nd_test_bearing_2.csv"
        match = re.search(r'(1st_test|2nd_test).*bearing[_\s]*(\d)', filename, re.IGNORECASE)
        if not match:
            return None
        
        test_set = match.group(1)
        bearing_id = int(match.group(2))
        
        # ê³ ì¥ ì‹œì‘ ì§€ì  ê°€ì ¸ì˜¤ê¸°
        anomaly_config = config.get('labels', {}).get('anomaly', {})
        
        if test_set == '1st_test':
            # TEST1ì€ ê³ ì¥ì´ ì—†ê±°ë‚˜ ê¸°ë¡ ì¢…ë£Œ ì§€ì  ì‚¬ìš©
            limit_key = f'test1_bearing_{bearing_id}_limit'
            failure_start = anomaly_config.get(limit_key, None)
            has_failure = False
            status = "ì •ìƒ (ê¸°ë¡ ì¢…ë£Œ)"
        else:
            # TEST2ëŠ” ê³ ì¥ ì‹œì‘ ì§€ì  ì‚¬ìš©
            failure_key = f'bearing_{bearing_id}_failure_start'
            failure_start = anomaly_config.get(failure_key, None)
            has_failure = failure_start is not None
            status = "ê³ ì¥ ë°œìƒ" if has_failure else "ì •ìƒ"
        
        if failure_start is None:
            return None
        
        # ìƒ˜í”Œ ìˆ˜ë¥¼ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (20kHz ê¸°ì¤€)
        failure_time_sec = failure_start * 20480 / 20000  # íŒŒì¼ë‹¹ 20480 ìƒ˜í”Œ, 20kHz
        
        return {
            'test_set': test_set,
            'bearing_id': bearing_id,
            'failure_start': failure_start,
            'failure_time_sec': failure_time_sec,
            'has_failure': has_failure,
            'status': status
        }
    except Exception as e:
        return None

# Page config
st.set_page_config(
    page_title="ì´ìƒ íƒì§€ (Anomaly Detection)",
    page_icon="ğŸ”",
    layout="wide"
)

# Initialize
init_session_state()
request_notification_permission()
api_client = get_api_client()

# Title
st.title("ğŸ” ë² ì–´ë§ ì´ìƒ íƒì§€")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # Threshold slider
    # Get model threshold from API
    try:
        model_info = api_client.get_model_info()
        default_threshold = model_info.get('threshold', 2.890021)
    except:
        default_threshold = 2.890021  # v2 model threshold fallback
    
    threshold = st.slider(
        "íƒì§€ ì„ê³„ê°’ (Detection Threshold)",
        min_value=0.1,
        max_value=10.0,
        value=default_threshold if get_threshold() == 6.995087 else get_threshold(),  # Update if old v1 threshold
        step=0.01,
        help=f"ëª¨ë¸ ê¸°ë³¸ ì„ê³„ê°’: {default_threshold:.6f}. ë†’ì„ìˆ˜ë¡ ëœ ë¯¼ê° (ë” ì ì€ ì´ìƒ íƒì§€)"
    )
    set_threshold(threshold)

    st.markdown("---")

    # API Status
    st.subheader("ğŸŒ API ìƒíƒœ")
    try:
        health = api_client.health_check()
        if health.get("models_loaded"):
            st.success("âœ… API ì—°ê²°ë¨")
            st.caption(f"ëª¨ë¸ ë¡œë“œë¨: {health.get('models_loaded')}")
        else:
            st.warning("âš ï¸ API ì‹¤í–‰ ì¤‘ì´ë‚˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
    except Exception as e:
        st.error("âŒ API ì—°ê²° ì•ˆë¨")
        st.caption(str(e))
    
    st.markdown("---")
    
    # Sample Data Section
    st.subheader("ğŸ“¦ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ë°ì´í„°")
    st.caption("ì›¹ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”")
    
    # Load test data info
    test_data_info_path = Path("data/samples/web_test/test_data_info.json")
    if test_data_info_path.exists():
        import json
        with open(test_data_info_path, 'r', encoding='utf-8') as f:
            test_data_info = json.load(f)
        
        # Normal data
        st.markdown("**ì •ìƒ ë°ì´í„°:**")
        for dataset in test_data_info.get('normal_datasets', []):
            file_path = Path("data/samples/web_test") / dataset['file']
            if file_path.exists():
                with open(file_path, 'rb') as f:
                    st.download_button(
                        label=f"ğŸ“„ {dataset['file']} (ì˜ˆìƒ: {dataset['expected_anomaly_rate']})",
                        data=f.read(),
                        file_name=dataset['file'],
                        mime="text/csv",
                        help=f"ì¶œì²˜: {dataset['source']}, ìƒ˜í”Œ: {dataset['samples']:,}ê°œ, ì˜ˆìƒ í‰ê·  ì˜¤ì°¨: {dataset['expected_mean_error']}"
                    )
        
        st.markdown("**ì´ìƒ ë°ì´í„°:**")
        for dataset in test_data_info.get('anomaly_datasets', []):
            file_path = Path("data/samples/web_test") / dataset['file']
            if file_path.exists():
                with open(file_path, 'rb') as f:
                    st.download_button(
                        label=f"ğŸ“„ {dataset['file']} (ì˜ˆìƒ: {dataset['expected_anomaly_rate']})",
                        data=f.read(),
                        file_name=dataset['file'],
                        mime="text/csv",
                        help=f"ì¶œì²˜: {dataset['source']}, ìƒ˜í”Œ: {dataset['samples']:,}ê°œ, ì˜ˆìƒ í‰ê·  ì˜¤ì°¨: {dataset['expected_mean_error']}"
                    )
    else:
        st.info("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `generate_test_data_for_web.py`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# Main content
tab1, tab2, tab3 = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“Š ê²°ê³¼", "ğŸ“œ íˆìŠ¤í† ë¦¬"])

with tab1:
    st.subheader("ğŸ“ CSV íŒŒì¼ ì—…ë¡œë“œ")
    st.markdown("ë² ì–´ë§ ì§„ë™ ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ìµœì†Œ 2048ê°œ ìƒ˜í”Œ)")

    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ ì„ íƒ",
        type=["csv"],
        help="CSV í˜•ì‹: timestamp, value (ë˜ëŠ” timestamp, ch1, ch2, ...)"
    )

    if uploaded_file:
        # Preview
        with st.expander("ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            try:
                df = pd.read_csv(uploaded_file)
                st.write(f"**í¬ê¸°**: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
                st.dataframe(df.head(10), use_container_width=True)

                # Reset file pointer
                uploaded_file.seek(0)
            except Exception as e:
                show_error_alert(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {str(e)}")

        # Detect button
        if st.button("ğŸ” ì´ìƒ íƒì§€ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
                try:
                    # Call API
                    result = api_client.detect_anomaly_file(
                        file_bytes=uploaded_file.getvalue(),
                        filename=uploaded_file.name,
                        threshold=threshold
                    )

                    # Save to session state
                    st.session_state.last_result = result
                    st.session_state.last_filename = uploaded_file.name

                    # Add to history
                    add_to_history(
                        timestamp=datetime.now(),
                        filename=uploaded_file.name,
                        anomalies=result['anomalies_detected'],
                        total=result['total_sequences'],
                        threshold=threshold
                    )

                    st.success("âœ… íƒì§€ ì™„ë£Œ!")
                    st.balloons()

                except Exception as e:
                    st.exception(e)
                    show_error_alert(f"íƒì§€ ì‹¤íŒ¨: {str(e)}")

with tab2:
    st.subheader("ğŸ“Š íƒì§€ ê²°ê³¼")

    if st.session_state.get('last_result'):
        result = st.session_state.last_result

        # Alert
        show_anomaly_alert(
            anomalies_detected=result['anomalies_detected'],
            total_sequences=result['total_sequences'],
            anomaly_rate=result['anomaly_rate'],
            send_browser_notif=True
        )

        st.markdown("---")

        # Expected vs Actual Comparison (if test data)
        test_data_info_path = Path("data/samples/web_test/test_data_info.json")
        if test_data_info_path.exists():
            import json
            with open(test_data_info_path, 'r', encoding='utf-8') as f:
                test_data_info = json.load(f)
            
            # Find matching dataset
            all_datasets = test_data_info.get('normal_datasets', []) + test_data_info.get('anomaly_datasets', [])
            matching_dataset = None
            if st.session_state.get('last_filename'):
                for dataset in all_datasets:
                    if dataset['file'] in st.session_state.last_filename:
                        matching_dataset = dataset
                        break
            
            if matching_dataset:
                st.info(f"""
                **ğŸ“Š ì˜ˆìƒ ê²°ê³¼ (Expected):**
                - ì´ìƒ íƒì§€ìœ¨: {matching_dataset['expected_anomaly_rate']}
                - í‰ê·  ì¬êµ¬ì„± ì˜¤ì°¨: {matching_dataset['expected_mean_error']}
                - ìµœëŒ€ ì¬êµ¬ì„± ì˜¤ì°¨: {matching_dataset['expected_max_error']}
                
                **ğŸ“ˆ ì‹¤ì œ ê²°ê³¼ (Actual):**
                - ì´ìƒ íƒì§€ìœ¨: {result['anomaly_rate']*100:.2f}%
                - í‰ê·  ì¬êµ¬ì„± ì˜¤ì°¨: {np.mean(result.get('reconstruction_errors', [0])):.6f}
                - ìµœëŒ€ ì¬êµ¬ì„± ì˜¤ì°¨: {np.max(result.get('reconstruction_errors', [0])):.6f}
                """)
        
        # Metrics
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="ì „ì²´ ì‹œí€€ìŠ¤ (Total Sequences)",
                value=result['total_sequences']
            )

        with col2:
            st.metric(
                label="ì´ìƒ íƒì§€ ê°œìˆ˜ (Anomalies)",
                value=result['anomalies_detected'],
                delta=f"{result['anomaly_rate']:.1%}",
                delta_color="inverse"
            )

        with col3:
            st.metric(
                label="ì„ê³„ê°’ (Threshold)",
                value=f"{result['threshold']:.4f}"
            )

        with col4:
            st.metric(
                label="ì²˜ë¦¬ ì‹œê°„ (Processing Time)",
                value=f"{result['processing_time_ms']:.0f} ms"
            )

        st.markdown("---")

        # ê³ ì¥ êµ¬ê°„ ì •ë³´ í‘œì‹œ
        failure_info = get_failure_info(st.session_state.get('last_filename', ''))
        if failure_info:
            st.markdown("---")
            st.subheader("âš ï¸ ê³ ì¥ êµ¬ê°„ ì •ë³´")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ê³ ì¥ ì‹œì‘ ì§€ì ", f"{failure_info['failure_start']:,} ìƒ˜í”Œ")
            with col2:
                st.metric("ê³ ì¥ ì‹œì‘ ì‹œê°„", f"{failure_info['failure_time_sec']:.1f}ì´ˆ")
            with col3:
                st.metric("ìƒíƒœ", failure_info['status'])
            
            if failure_info['has_failure']:
                st.warning(f"âš ï¸ ì´ ë² ì–´ë§ì€ ì•½ {failure_info['failure_time_sec']:.1f}ì´ˆ ì§€ì ë¶€í„° ê³ ì¥ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # Visualizations
        errors = np.array(result['reconstruction_errors'])
        anomaly_indices = result['anomaly_indices']

        # ê³ ì¥ ì‹œì‘ ì§€ì  ê³„ì‚° (ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜)
        failure_start_seq = None
        if failure_info and failure_info.get('failure_start'):
            # ê³ ì¥ ì‹œì‘ ìƒ˜í”Œì„ ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
            # ì‹œí€€ìŠ¤ ê¸¸ì´: 2048, overlap: 50% -> step: 1024
            # failure_startëŠ” íŒŒì¼ ë²ˆí˜¸ì´ë¯€ë¡œ, ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜ í•„ìš”
            # ëŒ€ëµì ì¸ ë³€í™˜: íŒŒì¼ ë²ˆí˜¸ * (20480 / 1024) = íŒŒì¼ ë²ˆí˜¸ * 20
            failure_start_seq = int(failure_info['failure_start'] * 20)
            if failure_start_seq >= len(errors):
                failure_start_seq = len(errors) - 1
        
        # Reconstruction error plot
        st.plotly_chart(
            plot_reconstruction_error(
                errors=errors,
                threshold=result['threshold'],
                anomaly_indices=anomaly_indices,
                failure_start=failure_start_seq
            ),
            use_container_width=True
        )

        # Two columns for additional plots
        col_left, col_right = st.columns(2)

        with col_left:
            # Error distribution
            st.plotly_chart(
                plot_anomaly_distribution(errors, result['threshold']),
                use_container_width=True
            )

        with col_right:
            # Statistics
            st.subheader("ğŸ“ˆ í†µê³„")
            st.write(f"**í‰ê·  ì˜¤ì°¨ (Mean Error)**: {errors.mean():.6f}")
            st.write(f"**í‘œì¤€í¸ì°¨ (Std Error)**: {errors.std():.6f}")
            st.write(f"**ìµœëŒ€ ì˜¤ì°¨ (Max Error)**: {errors.max():.6f}")
            st.write(f"**ìµœì†Œ ì˜¤ì°¨ (Min Error)**: {errors.min():.6f}")
            st.write(f"**ì¤‘ê°„ê°’ (Median Error)**: {np.median(errors):.6f}")

            if len(anomaly_indices) > 0:
                st.markdown("---")
                st.subheader("âš ï¸ ì´ìƒ ì¸ë±ìŠ¤")
                st.write(anomaly_indices[:20])  # Show first 20
                if len(anomaly_indices) > 20:
                    st.caption(f"... ì™¸ {len(anomaly_indices) - 20}ê°œ ë”")

        # FFT Analysis
        if uploaded_file:
            st.markdown("---")
            st.subheader("ğŸ“Š ì£¼íŒŒìˆ˜ ë¶„ì„ (FFT)")

            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file)

                # Get signal data (column 1)
                signal = df.iloc[:10000, 1].values  # First 10k samples

                st.plotly_chart(
                    plot_fft_spectrum(signal, sampling_rate=2000),
                    use_container_width=True
                )
            except Exception as e:
                show_info_alert(f"FFT ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

    else:
        show_info_alert("ğŸ“ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  'ì´ìƒ íƒì§€ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")

with tab3:
    history_table_component()

# Footer
st.markdown("---")
st.caption("NASA ë² ì–´ë§ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ | LSTM Autoencoder v1.0")
